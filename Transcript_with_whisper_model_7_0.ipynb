{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0hea1kZrkDlX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48b4ede-d651-45e3-9cda-7832b0196400"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# upload audio file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "shutil.copy(\"/content/drive/MyDrive/Audio/test.wav\",\"/content/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "A6kwp21ljjj9",
        "outputId": "39da5e28-eb56-4779-a366-69aaea7d3fa4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/test.wav'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update -qq\n",
        "!apt-get install -y locales\n",
        "!locale-gen en_US.UTF-8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SazheB5jlRw",
        "outputId": "c4fb4514-9752-4760-9b3f-1e844b5d1968"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "locales is already the newest version (2.31-0ubuntu9.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Generating locales (this might take a while)...\n",
            "  en_US.UTF-8... done\n",
            "Generation complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LC_ALL'] = 'en_US.UTF-8'\n",
        "os.environ['LANG'] = 'en_US.UTF-8'"
      ],
      "metadata": {
        "id": "qWo8vB0pjnkg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git > /dev/null\n",
        "!pip install -q git+https://github.com/pyannote/pyannote-audio > /dev/null\n",
        "!pip install -q spacy\n",
        "!pip install -q sentencepiece\n",
        "!pip install -q bert-extractive-summarizer\n",
        "\n",
        "import subprocess \n",
        "from tqdm import tqdm \n",
        "import whisper \n",
        "\n",
        "import torch \n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "\n",
        "import json\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from summarizer import Summarizer \n",
        "from transformers import AutoModelForSeq2SeqLM,AutoTokenizer \n",
        "import datetime,time\n",
        " \n",
        "import pyannote.audio \n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "\n",
        "from pyannote.audio import Audio \n",
        "from pyannote.core import Segment \n",
        "\n",
        "import wave \n",
        "import contextlib "
      ],
      "metadata": {
        "id": "Ti2a8kJkYb8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81ae17b2-8704-4e26-e5e9-8e6e89db4bef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Vdbad9x5CHkC"
      },
      "outputs": [],
      "source": [
        "# Set input parameters\n",
        "path = \"/content/drive/MyDrive/Audio/test.wav\"\n",
        "model_size = \"medium\"\n",
        "language = \"English\"\n",
        "\n",
        "# Split filename and remove file extension\n",
        "filename = path.split(\"/\")[-1][:-3].split(' ')\n",
        "\n",
        "# Set model name based on language and model size\n",
        "model_name = model_size\n",
        "if language == 'English' and model_size != 'medium':\n",
        "    model_name += '.en'\n",
        "\n",
        "# Convert input file to WAV format if not already in WAV format\n",
        "if path[-3:] != 'wav':\n",
        "    subprocess.call(['ffmpeg', '-i', path, 'audio.wav', '-y'])\n",
        "    path = 'audio.wav'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxYITgmGfR9p",
        "outputId": "d11fc048-7a5e-4e52-d921-afee8c99243a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|█████████████████████████████████████| 1.42G/1.42G [01:12<00:00, 21.0MiB/s]\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "# define model parameters and load model\n",
        "# Transformer based Seq2Seq model trained on weak supervision\n",
        "\"\"\"\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(model_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "    Performs speaker verification using cosine distance between speaker embeddings\n",
        "    \n",
        "    # dict_keys(['text', 'segments', 'language'])\n",
        "    id : id of audio chunk/segment \n",
        "    start & end : start & end time of audio chunk\n",
        "    text : transcribed text\n",
        "    tokens : generated token list\n",
        "    temperature : non-deterministic factor (0 means deterministic model)\n",
        "    avg_logprob : uses additive margin softmax loss \n",
        "    compression_ratio : .WAV is windows compressed but .wav is uncompressed\n",
        "    no_speech_prob : probability of silence detection\n",
        "\"\"\"\n",
        "\n",
        "# Transcribe the audio using the Whisper model\n",
        "result = model.transcribe(path)\n",
        "segments = result[\"segments\"]"
      ],
      "metadata": {
        "id": "kwlvteAdhlaI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usQbmQ6zmkTv",
        "outputId": "06b94663-1a70-4b4a-bde8-fe81e14c8500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "18it [00:00, 106785.67it/s]\n"
          ]
        }
      ],
      "source": [
        "# Open output file for writing the transcription\n",
        "f = open(f\"{filename[0] if len(filename) > 0 else 'default'}_{filename[1] if len(filename) > 1 else 'transcript'}_whisper_transcript.txt\", \"w\")\n",
        "text = \"\"\n",
        "\n",
        "# Iterate through segments and write the transcribed text to the output file\n",
        "for (i, segment) in tqdm(enumerate(segments)):\n",
        "    try:\n",
        "        if \"text\" in segment and len(segment[\"text\"]) > 1:\n",
        "            f.write(segment[\"text\"][1:] + ' ')\n",
        "    except Exception as e:\n",
        "        print(f\"Error at segment {i}: {segment}\")\n",
        "        print(f\"Error details: {e}\")\n",
        "        continue"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}