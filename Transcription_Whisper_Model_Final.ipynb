{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hea1kZrkDlX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/openai/whisper.git > /dev/null\n",
        "\n",
        "import shutil,os\n",
        "import subprocess\n",
        "import random,torch\n",
        "import whisper\n",
        "\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)"
      ],
      "metadata": {
        "id": "Ti2a8kJkYb8U"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Vdbad9x5CHkC"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "# define model parameters and load model\n",
        "# Transformer based Seq2Seq model trained on weak supervision\n",
        "\"\"\"\n",
        "model_size = \"medium\"     # ['tiny', 'base', 'small', 'medium', 'large']\n",
        "language = \"English\"      # ['any', 'English']\n",
        "\n",
        "\n",
        "model_name = model_size\n",
        "if language == 'English' and model_size != 'large':\n",
        "  model_name += '.en'\n",
        "\n",
        "model = whisper.load_model(model_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxYITgmGfR9p",
        "outputId": "f6d4f3a8-1c81-4421-92e0-a1df4921c4bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# upload audio file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_transcript(path):\n",
        "\n",
        "  # copy file to current working directory from google drive\n",
        "\n",
        "  shutil.copy(path,os.getcwd())\n",
        "  path = path.split(\"/\")[-1]\n",
        "  filename = path[:-4].split(' ')\n",
        "  if len(filename)==1:\n",
        "    filename = filename[0]\n",
        "  else:\n",
        "    filename=f\"{filename[0]}{filename[1]}\"\n",
        "  \n",
        "  # if file is not in wav format convert it to wave format\n",
        "  if path[-3:] != 'wav':\n",
        "    subprocess.call(['ffmpeg', '-i', path, 'audio.wav', '-y'])\n",
        "    os.remove(path)\n",
        "    path = 'audio.wav'\n",
        "\n",
        "  print(\"File conversion - Done,Now Transcribing\")\n",
        "\n",
        "  \"\"\"\n",
        "    Performs speaker verification using cosine distance between speaker embeddings\n",
        "    \n",
        "    # dict_keys(['text', 'segments', 'language'])\n",
        "    id : id of audio chunk/segment \n",
        "    start & end : start & end time of audio chunk\n",
        "    text : transcribed text\n",
        "    tokens : generated token list\n",
        "    temperature : non-deterministic factor (0 means deterministic model)\n",
        "    avg_logprob : uses additive margin softmax loss \n",
        "    compression_ratio : .WAV is windows compressed but .wav is uncompressed\n",
        "    no_speech_prob : probability of silence detection\n",
        "  \"\"\"\n",
        "\n",
        "  result = model.transcribe(path)\n",
        "  segments = result[\"segments\"]\n",
        "\n",
        "\n",
        "  f = open(f\"{filename}.txt\", \"w\")\n",
        "\n",
        "  text = \"\"\n",
        "  \"\"\"\n",
        "  segment : new addition words : list and speaker : str\n",
        "  \"\"\"\n",
        "  for (i, segment) in enumerate(segments):\n",
        "      try:\n",
        "        f.write(segment[\"text\"][1:] + '\\n\\n') \n",
        "      except:\n",
        "        continue\n",
        "  f.close()\n",
        "\n",
        "  # remove audio.wav\n",
        "  os.remove(\"audio.wav\")\n",
        "\n",
        "  print(f\"Transcription - Done,check {filename}.txt\")\n"
      ],
      "metadata": {
        "id": "kwlvteAdhlaI"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLl07gbrQGF7"
      },
      "source": [
        "change to filename you want to transcribe - \"/content/drive/MyDrive/Audios/April 2.WAV\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usQbmQ6zmkTv",
        "outputId": "efabe6fa-bf9d-4d01-881c-f801d642abc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File conversion - Done,Now Transcribing\n",
            "Transcription - Done,check April2.txt\n"
          ]
        }
      ],
      "source": [
        "\n",
        "path = \"/content/drive/MyDrive/Audios/April 2.WAV\"\n",
        "\n",
        "generate_transcript(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "YUhvvhpalAmN"
      },
      "outputs": [],
      "source": [
        "#"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}